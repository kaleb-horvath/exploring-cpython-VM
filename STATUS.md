### current status
trying to get a functional tokenizer working. currently at the step of matching each token to ensure validity before
returning the token stream. implement syntax exceptions and string literals into lex regex pattern.